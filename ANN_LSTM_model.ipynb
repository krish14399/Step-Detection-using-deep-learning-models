{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Group M\n",
    "\n",
    "Team Members:\n",
    "1. Akshay Augustine Sheby - 5123774\n",
    "2. Krishnapriya Krishnan Santhadevi - 5123779\n",
    "3. Megha Eldho - 5123773\n",
    "4. Ranjitha Umesh - 5123734\n",
    "\n",
    "# LSTM model\n",
    "We have tested 3 different algorithms such as GRU, LSTM and CNN. From these 3 algorithms we found LSTM as the best algorithm, because it is giving better accuracies when compared with other algorithms. We have created seperate jupyter notebooks for data preprocessing, LSTM model, GRU model and CNN model.\n",
    "\n",
    "We tried different approaches for labelling the start step and end step. \n",
    "1. We created one single column for the label, named 'step_labels'. From the first row of .csv.stepMixed file we took the start step index value and identified that indexed row in the .csv file then we marked 'step_labels' column as 1. Then we took the end step index value and identified that indexed row in the .csv file then we marked 'step_labels' column as 1. We gave 0 for all other rows with indexes not listed in the .csv.stepMixed file. We got a maximum precision score on the test dataset as 0.44944.\n",
    "2. We created two seperate columns for labels, one is 'start_step_label' and other one is 'end_step_label'. From the first row of .csv.stepMixed file we took the start step index value and identified that indexed row in the .csv file then we marked 'start_step_label' column as 1. Then we took the end step index value and identified that indexed row in the .csv file then we marked 'end_step_label' column as 1. We gave 0 for all other remaining unknown rows in the columns 'start_step_label' and 'end_step_label'. We got a maximum precision score on the test dataset as 0.58124.\n",
    "3. Then for the previously labelled columns, instead of giving all the unknown values as 0, we tried implementing linear interpolations, but it didn't upgrade the score and accuracy.\n",
    "4. Then we applied mean value for the unknown values in the label columns, but it also didn't work out well.\n",
    "5. Then we changed the way of labelling, we labelled all the 10 rows after the valid start step index as 1 and all the 10 rows before the valid end step index as 1. It also didn't gave good accuracy.\n",
    "6. Then we labelled 1 row before and after the valid start step index and valid end step index as 1. We got a maximum precision score on the test dataset as 0.62397, which is the best score we obtained.\n",
    "7. Then we labelled 2, 3, 4 and 5 rows before and after the valid start step index and valid end step index as 1. It was also not good.\n",
    "\n",
    "We tried different algorithms in which LSTM performed well because of these reasons:\n",
    "- LSTM got better results when compared with others. LSTM model performed well for handling sequential data and capturing long-term dependencies. LSTMs can effectively learn patterns and dependencies in the data over long time horizons. LSTMs have memory cells that allow them to store and retrieve information over time, making them capable of capturing long-term dependencies in the data. \n",
    "- GRU got the results similar to LSTM. GRU models are simplified variant of LSTM that aim to strike a balance between complexity and performance. GRUs also perform well in capturing temporal dependencies in time series data. GRU is easier to implement and train. \n",
    "- CNN results were not good because it is not good for handling large datasets of sequential data. CNNs are primarily designed for image processing tasks but can also be adapted for time series prediction. While not specifically designed for sequential data, CNNs can still capture local patterns and temporal correlations in time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_E7aN1WU5qWy",
    "outputId": "f5b77731-9258-48e1-e36e-1cd806c41bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  AccelX_5  AccelY_5  AccelZ_5   GyroX_5   GyroY_5   \n",
      "0                0  1.370639  3.077730 -9.138201  0.026021 -0.025069  \\\n",
      "1                1  1.380689  3.039416 -9.200333  0.038649 -0.038450   \n",
      "2                2  1.378264  2.981465 -9.305405  0.043459 -0.038100   \n",
      "3                3  1.423814  2.944719 -9.343213  0.042548 -0.028578   \n",
      "4                4  1.422443  2.946009 -9.392369  0.027376 -0.014168   \n",
      "...            ...       ...       ...       ...       ...       ...   \n",
      "722577      722577 -0.572854  7.180082  6.513024  0.001732  0.005325   \n",
      "722578      722578 -0.538156  7.221120  6.618960  0.001231  0.003183   \n",
      "722579      722579 -0.520193  7.248638  6.627628  0.001357  0.013642   \n",
      "722580      722580 -0.527089  7.316613  6.646155  0.008508  0.025486   \n",
      "722581      722581 -0.503076  7.346765  6.589603  0.011767  0.025111   \n",
      "\n",
      "         GyroZ_5  start_step_labels  end_step_labels  \n",
      "0       0.026772                0.0              0.0  \n",
      "1       0.035676                0.0              0.0  \n",
      "2       0.031424                0.0              0.0  \n",
      "3       0.029073                0.0              0.0  \n",
      "4       0.016098                0.0              0.0  \n",
      "...          ...                ...              ...  \n",
      "722577  0.004659                0.0              0.0  \n",
      "722578  0.008544                0.0              0.0  \n",
      "722579  0.009637                0.0              0.0  \n",
      "722580  0.007495                0.0              0.0  \n",
      "722581  0.007824                0.0              0.0  \n",
      "\n",
      "[722582 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Preparation\n",
    "\n",
    "# Load input features from a CSV file\n",
    "file_path = 'Kaggle competition dataset/data_full.csv'\n",
    "datasets = pd.read_csv(file_path)\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dGT4lIq36Bbm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): LSTM(6, 32, batch_first=True)\n",
       "    (1): LSTM(32, 16, batch_first=True)\n",
       "    (2): LSTM(16, 8, batch_first=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=8, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Convert input features and labels to PyTorch tensors\n",
    "X = torch.tensor(datasets.values[:,1:7], dtype=torch.float64)\n",
    "y = torch.tensor(datasets.values[:,7:9], dtype=torch.int64)\n",
    "\n",
    "# ove the input features and labels to the specified device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "\n",
    "# 2. LSTM Model Definition\n",
    "\n",
    "#Define the LSTMModel class inheriting from nn.Module\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.num_layers = len(hidden_sizes)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_layers.append(nn.LSTM(input_size, hidden_sizes[0], batch_first=True))\n",
    "        for i in range(self.num_layers - 1):\n",
    "            self.hidden_layers.append(nn.LSTM(hidden_sizes[i], hidden_sizes[i+1], batch_first=True))\n",
    "        self.fc = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    #Define the forward pass of the model, where the input passes through the LSTM layers\n",
    "    def forward(self, x):\n",
    "        output, _ = self.hidden_layers[0](x)\n",
    "        for i in range(1, self.num_layers):\n",
    "            output, _ = self.hidden_layers[i](output)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    \n",
    "# 3. Hyperparameters and Model Initialization\n",
    "input_size = 6\n",
    "hidden_sizes = [32, 16, 8]\n",
    "output_size = 2  # 0 or 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "#Create an instance of the LSTM model and move it to the specified device\n",
    "model = LSTMModel(input_size, hidden_sizes, output_size).to(device)\n",
    "\n",
    "#Ensure that the data type of the model's parameters match the data type of the input features(float64)\n",
    "model.to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfi4rm5MBZii",
    "outputId": "ac7f063c-1987-4fb1-be7a-7bd53fbae11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 4.1210, Train Accuracy: 64.19873453808704\n",
      "Epoch [2/10], Train Loss: 4.0136, Train Accuracy: 67.4896413140654\n",
      "Epoch [3/10], Train Loss: 3.9780, Train Accuracy: 68.62155437029985\n",
      "Epoch [4/10], Train Loss: 3.9513, Train Accuracy: 68.33217544859961\n",
      "Epoch [5/10], Train Loss: 3.9335, Train Accuracy: 68.94463188952949\n",
      "Epoch [6/10], Train Loss: 3.9189, Train Accuracy: 68.9068507103692\n",
      "Epoch [7/10], Train Loss: 3.9069, Train Accuracy: 69.12731011843638\n",
      "Epoch [8/10], Train Loss: 3.8964, Train Accuracy: 68.20769130700737\n"
     ]
    }
   ],
   "source": [
    "# Create a data loader\n",
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 4. Training loop\n",
    "\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "\n",
    "#Iterate over the specified number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    #Initialize variables for tracking loss and accuracy\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    #Data is iterated through the data loader in batches\n",
    "    for inputs, targets in dataloader: #batch inputs and targets\n",
    "        #Convert inputs and targets to appropriate data types\n",
    "        inputs = inputs.to(device) #shape: [64, 6] [batch_size, num_inp_features]\n",
    "        targets = targets.to(device) #shape: [64] [batch_size]\n",
    "\n",
    "        #Perform forward pass through the model\n",
    "        outputs = model(inputs) #shape: [64, 2] [batch_size, num_of_classes]\n",
    "        \n",
    "        # Calculate loss\n",
    "        start_pred = outputs[:, 0]\n",
    "        end_pred = outputs[:, 1]\n",
    "        \n",
    "        start_target = targets[:, 0]\n",
    "        end_target = targets[:, 1]\n",
    "        \n",
    "        # Convert the outputs to float tensor\n",
    "        start_pred = start_pred.float()\n",
    "        end_pred = end_pred.float()\n",
    "        \n",
    "        # Convert the targets to long (integer) tensor\n",
    "        start_target = start_target.float()\n",
    "        end_target = end_target.float()\n",
    "        \n",
    "        #Calculate the loss using loss function\n",
    "        start_loss = criterion(start_pred, start_target)\n",
    "        end_loss = criterion(end_pred, end_target)\n",
    "\n",
    "        # Clear the gradients before backward pass, it ensures that the gradients from previous iterations are cleared before calculating new gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Perform a single backward pass by taking average of start step loss and end step loss\n",
    "        loss = (start_loss + end_loss) / 2\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update the neural network parameters based on the gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        #Update training loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        #Make sure the outputs have appropriate shape and are in the range of [0, 1] using a sigmoid activation function\n",
    "        start_pred = torch.sigmoid(start_pred)\n",
    "        end_pred = torch.sigmoid(end_pred)\n",
    "        \n",
    "        start_pred = start_pred.round()\n",
    "        end_pred = end_pred.round()\n",
    "\n",
    "        #Update training accuracy     \n",
    "        total += start_target.size(0)\n",
    "        total += end_target.size(0)\n",
    "        \n",
    "        correct += (start_pred == start_target).sum().item()  \n",
    "        correct += (end_pred == end_target).sum().item()\n",
    "\n",
    "    #Calculate average training loss\n",
    "    train_loss = train_loss / len(dataset)\n",
    "    \n",
    "    #Calculate average training accuracy\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    #Append the training loss and accuracy to seperate lists to plot the graph\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    # Print the training loss and accuracy for the current epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualization\n",
    "\n",
    "#Plot the training accuracy graph\n",
    "plt.plot(range(1, num_epochs+1), train_accuracy_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Accuracy')\n",
    "plt.title('Training Accuracy vs. Epochs')\n",
    "plt.show()\n",
    "\n",
    "#Plot the training loss graph\n",
    "plt.plot(range(1, num_epochs+1), train_loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.title('Training Loss vs. Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JtTk1btCTm3"
   },
   "outputs": [],
   "source": [
    "# 6. Test Data and Prediction\n",
    "\n",
    "df_test_data = pd.read_csv(\"testdata.csv\")\n",
    "print(df_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "#Convert the test data to a PyTorch tensor\n",
    "test_inputs = torch.tensor(df_test_data.values, dtype=torch.float64)\n",
    "\n",
    "#Move the test inputs to the specified device\n",
    "test_inputs = test_inputs.to(device)\n",
    "\n",
    "#Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "#Perform forward pass on the test data and obtain predictions for start step and end step probabilities\n",
    "with torch.no_grad():\n",
    "    out = model(test_inputs)\n",
    "    print(out)\n",
    "    start_prob = out[:, 0]\n",
    "    end_prob = out[:, 1]\n",
    "    start_prob = torch.sigmoid(start_prob)\n",
    "    end_prob = torch.sigmoid(end_prob)\n",
    "\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pd.DataFrame({'index': range(len(test_inputs)), 'start': start_prob.round(), 'end': end_prob.round()})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "outputs.to_csv('output7_lstm_8.csv', index=False)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
